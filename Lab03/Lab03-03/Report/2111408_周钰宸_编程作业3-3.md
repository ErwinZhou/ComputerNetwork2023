# Computer Network2023

## Lab03-03 **基于滑动窗口的流量控制机制+选择确认**

#### 学号：2111408	专业：信息安全	姓名：周钰宸

### 1 实验原理

​	之前在Lab03-02中我们基于对滑动窗口上的流量控制和累积确认GBN在提高了链路利用率的同时，实现了保序的传输。不过**累积确认存在一个问题**就是当窗口和带宽的时延都较大时，单个分组的差错可能会引起**GBN重传大量的分组**，然后许多本来不用重传的分组会充斥在信道中，造成**资源浪费。**

​		因此本次我们会进一步实现滑动窗口中的另一个特殊机制，**即在接收端滑动窗口（缓冲区）大于1的情况下，实现选择确认。**这可以让让发送方仅重传那些丢失和受损的分组而**避免不必要的重传。**

#### 1.1 滑动窗口

上次实验中，已经介绍过了滑动窗口协议，**这里不再赘述细节，我会强调一些本次实验会用到的重点。**

1. 发送缓冲区：
   
   * 发送端的滑动窗口：其本质是发送缓冲区内容的一个子集，那些已发送但是未经确认分组的序号构成的空间。**本次实验实现过程也是遵循这个概念，即我的发送缓冲区是有固定大小的，而滑动窗口大小是会变化的。**

2. 接收缓冲区：
   * 接收端的滑动窗口：对于接收者来说，接收缓冲区就等于接收端的滑动窗口。**即二者大小一致。**
   * ==**接收窗口尺寸Wr>1时 ，则可以乱序接收（SR）。但提交给上层的分组，要按序。即本次实验需要着重考虑交付上层的顺序，因为接收端的滑动窗口本次可以进行缓存了。**==
   * 接收端滑动窗口的滑动和发送确认：
     * 滑动：
       * **低序号的分组到来，接收窗口移动；（所有机制！包括本次的SR）**
       * 高序号分组乱序到，**缓存但不交付（因为要实现RDT，不允许失序。即RDT的可靠要保证交付时的有序！），不滑动 （SR）。**
     * 发送确认：
       * 接收窗口尺寸>1 时， 收到分组，发送那个分组的确认。==**也就是说不论是否在接收端的滑动窗口范围内，都要发送对应的ACK，并且反馈的ACK不再具有累积确认的意义。是非累计确认！**==
   
3. 总结：计算机网络领域的滑动窗口协议本质上是一个更为通用的协议，而根据发送方和接受方的滑动窗口大小的不同情况，进一步分化出了停等机制、流水线协议（GBN与SR）。具体而言：

   * SW=1, RW=1:停等机制，RDT3.0；
   * SW>1, RW=1:流水线协议的累积确认GBN；
   * **SW>1, RW>1:流水写协议的选择性重发SR。**

   **由于本次实验进一步实现了流水线机制中的SR，后面只会简单说下流水线协议，再介绍下SR。**

#### 1.2 流水线协议

1. 流水线：允许发送方在未得到对方确认的情况下一次发送多个分组，允许在发送方和接收方之间并行处理多个数据单元。
2. 特点：

   * 多个序列号：上次提到过，使用多个序列号的目的是增加一些保序功能和容错机制，进一步保证RDT的可靠性。
   * 在发送方/接收方要有缓冲区：
   
     * 发送方缓冲：未得到确认，可能需要重传；
     * 接收方缓存：上层用户取用数据的速率≠接收到的数据速率；==**本次实验要加入接收方的缓存。因为接收到的数据可能乱序，排序交付（保证RDT的可靠！）**==
3. 两种同样的流水线协议：回退N步(GBN)和**选择重传(SR)。**

#### 1.3 SR（Selected Repeat）选择确认协议

简单来说，**<font size=3, color="red">SR和GBN的最大区别我认为其实就在一处，那就是SR的接收窗口尺寸大于1。</font>**这进一步的导致了它们之间的更多区别，包括SR即选择重传的由来。

1. **GBN和SR的区别：**
   * GBN：接收窗口尺寸=1。因此导致接收端只能够顺序接收，这实际上也就带来了累计确认的效果。因为接收方只有一个窗口大小，因此不在窗口内（尤其是提前到来的）的都不能被接收，故接收方的ACK带有了所谓的“之前的包我都收到了”的累积确认效果。
   * **SR：接收窗口尺寸大于1。**因此使得**接收端可以缓存提前到来的数据报而不是直接丢弃**，节省网络空间中的资源。但此时接收端回复的ACK自然就不再具有“前面的包我都收到了”的含义了，==**因为它可以提前收到一些乱序的包！**==这样的性质也进一步优化了发送端，**因此此时发送端只需要选择性重发对应的包就行，而不是全部重发。==即选择重发的由来。==**

2. **SR发送和接受双方：**
   * 发送端：
     * 发送端最多在流水线中有N个未确认的分组
     * 发送方为==**每个未确认的分组都要保持一个定时器，而不是一个唯一的全局定时器。**==当超时定时器到时，**只对那些没有收到ACK的分组进行重发。**
     * 发送窗口的最大值（发送缓冲区）限制发送未确认分组的个数。
   * 接收端：
     * 接收方对**每个到来的分组（只要校验和正确，只要不是大于最大窗口前沿。包括窗口内和窗口前的）单独确认==individual ack （非累计确认）==。**
     * 可以**缓存乱序的分组，最终将分组按顺序交付给上层。**

### 2 实验要求

*实验3-3：在实验3-1的基础上，将停等机制改成基于滑动窗口的流量控制机制，发送窗口和接收窗口采用相同大小，支持选择确认，完成给定测试文件的传输。*

### 3 前期准备

#### 3.1 UDP报文设计

```
 0              7 0             7 0                            15
+---------------------------------------------------------------+
| 				          Sequence Number                       |
+---------------------------------------------------------------+
|                       Acknowledgment Number                   |
+---------------------------------------------------------------+
|                              Flags   							|
+---------------------------------------------------------------+
|                             Checksum							|
+---------------------------------------------------------------+
|                          	Data  Length                        |
+---------------------------------------------------------------+
|                           Header Length                       |
+---------------------------------------------------------------+
|                                                               |
|							  	                                |
|                               Data                            |
|								                       	        |
|                                                               |
+---------------------------------------------------------------+
```

本次实验的UDP报文由于需要保证16位的对齐和一些数值类型转换，出于时间原因，设计的比较简单。其中各个字段含义不再赘述，只说明一下：

1. Sequence Number：序列号（u_short 16位）。
2. Acknowledgment Number：ACK值（u_short 16位）。
3. Flags：标志位（u_short 16位），暂时只是仿照了TCP设计了低五位，未来会继续拓展。具体而言：
   * SYN：0x1，
   * ACK：0x2
   * FIN：0x4，
   * LAS：0x8
   * RST：0x16，
4. Checksum：校验位（u_short 16位）
5. Data  Length：数据段长度（u_short 16位）
6. Header Length：报文头部长度（u_short 16位）

#### 3.2 协议设计

#### 3.2.1 三次握手（建立连接）

**这里和Lab03-01没有丝毫变化，可以跳过。详见我Lab03-01报告。**

这里建立连接的时候我采用的就是仿照TCP的三次握手进行设计，不过没有使用其中随机的客户端和服务器端的数据包序列号生成和ACK=序列号+1的验证机制。未来有待完善。

1. 客户端想要与服务器建立连接, 于是向服务器发送SYN报文请求连接。服务器知道客户端能够发送。
2. 服务器收到客户端的连接请求之后, 服务器向客户端发送确认报文ACK及请求连接报文SYN。让客户端知道服务器能够接收并且能够发送。
3. 客户端收到服务器的连接请求, 向服务器发送确认报文ACK。在服务器接收到ACK之后,服务器知道了客户端能够发送。

至此实现了客户端和服务器端都确认了彼此可以正常发送和接收数据，然后就可以开始正常通信了。**不过在这个过程中也可能存在超时或者丢包的情况，实际上都进行了多种异常情况的处理，具体处理详见我上次报告Lab03-01的4.3.2部分。**

#### 3.2.2 数据传输

这部分是本次修改的重点，**保持基于滑动窗口的流量控制机制，从支持GBN改为支持SR的选择确认。**

1. **滑动窗口：**
   * 客户端（发送方）：客户端的**发送缓冲区大小一次传输过程中固定（4-36）**，而**滑动窗口大小**即sendbase与nextseqnum之前部分，可以变化。
   * 服务器端（接收方）：服务器端的**发送缓冲区（滑动窗口）大小也是一样在一次传输过程中固定（4-36），==和客户端一样可以提前设定成二者发送缓冲区（也就是实验要求说的窗口）大小相同。不过由于实验要求是二者相同，因此后面我的一些错误处理也是暂时针对二者窗口大小相同设计的。==**

2. **SR选择确认：**

   * **客户端（发送方）：**

     |                             事件                             |                             动作                             |
     | :----------------------------------------------------------: | :----------------------------------------------------------: |
     | 从上层收到数据：当从上层接收到数据后，发送方检查下一个可用于该分组的序号。 |           若序号在发送方窗口内，则将数据打包并发送           |
     |                                                              |             否则：以后再传，等待窗口滑动将其罩住             |
     |               **超时：每个分组有自己的定时器**               |                 **超时后只能发送一个分组。**                 |
     | 收到ACK：将被确认的分组**标记为已接收(若该分组序号在窗口内)。** | 如果该分组的序号等于发送基序号send_base，*则窗口基序号向前移动到具最小序号的未确认分组处。* |
     |                                                              |    窗口移动后，仍有序号落在窗口内的未发送分组，继续发送。    |

     具体实现过程中，进一步采用了**多线程的机制。详见下面的多线程介绍。**

   * **服务器端（接收方）**

     |                           失序分组                           | 先被缓存，直到所有丢失分组（序号更小的分组）被收到为止，==才可将一批分组按序交付给上层。== |
     | :----------------------------------------------------------: | :----------------------------------------------------------: |
     | 序号在接收窗口内的分组被正确接收（没出现位错误）：收到的分组落在`[rcv_base，rcv_base+N-1]`内 | **接收并回发一个ACK。该分组以前没收到过：缓存**；否则直接丢弃。 |
     |                该分组的**序号等于接收基序号**                | 则该**==分组及已缓存的连续序号（一定得连续！）的分组交付==**（起始于基序号）给上层。接收窗口**按交付的分组数量向前移动。** |
     |     **收到序号在接收基序号以前**或者最大窗口以后的分组：     | 该分组是接收方以前已确认过的分组。**生成一个ACK， 并回发给发送方。** 如果接收方不确认，发送方窗口不能向前滑动。 |
     |                 其他情况（包括校验和出错等）                 |                          忽略该分组                          |

     实际上==**本次实验中由于要求设计接收方和发送方窗口大小一致，因此设计的即使接收到的序列号大于窗口以后（实际上在窗口大小相同情况下不可能发生）也发送ACK。**==不过如果遇到**真实的接收方和发送方窗口大小不同，则当收到大于接收窗口后端序列号的包时，不应该回复对应的ACK，因为没有进行缓存！**

3. **<font size=4, color="red">多线程：</font>**

   本次实验进一步采取了多线程的方式进行编程。==**其中包括双发的主线程在内，发送方一共具有四个线程，接收方一共具有三个线程。新加入的线程我会用亮体标出。具体而言：**==

   * **发送方（客户端）：**
     * **主线程（发送线程）：**握手挥手，send_data与rdt_send。数据传输中主要做的就是依次从最大的文件缓冲区file_data_buffer中依次取出数据分包发送。并进行窗口滑动。启动和回收另外三个线程。
     * **接收线程：**接受来自接收端的ACK，并进行窗口滑动。
     * **==超时重传线程：==**上次实验中，超时重传就是在接收线程中实现的。这是因为上次实验中只有一个超时定时器，因此每次判断是否超时只需要O（1）的时间，而本次遍历查看所有数据报的定时器则最大会需要O（n）级别的时间。**为了避免这样大量的时间在接收线程中浪费（遍历时没有进行recv_from，socket只会暂时缓存部分数据报）导致接收线程接收ACK的情况出现不稳定的变化，本次额外设定了这个超时重传线程。主要做的就是不停地遍历发送窗口中的数据报，重发超时的那个，并重新计时。**
     * **日志线程：**和Lab03-02一样，为了避免对cout或者说是控制台这个全局变量的竞争，采用消息队列的方式依次发送消息。
   * **接收方（服务器端）：**
     * **主线程（接收线程）：**握手挥手和rdt_rcv。主要用于不停的recv_from发送端发送的数据报，并根据数据报的校验和以及序列号等执行接下来的动作，包括**缓存数据报，上交数据报给应用层以及通知发送线程要发送的下一个序列号**等（实际上也是通过一个需要ACK的序号队列实现，详见代码部分）。
     * ==**发送线程：**==本次实验新增加的。主要根据需要ACK的序号队列，不停地发送对应的ACK。因为上次实验中接收方实际上是一个类似的停等机制，接收到一个序列号再发送对应的ACK即可，即处理完一个再看下一个（这其实是因为上次实验接收方不需要乱序接收的原因）**。不过由于本次对于一些乱序达到的数据报也需要接收。因此通过多线程将发送和接受分离开来，有利于及时处理达到的数据报（不这么做的话，send ACK时候不能recv_from，只能交给socket缓存），提高效率。**
     * **==日志线程：==**这个和Lab03-02不同。由于上次的接收方只有一个线程，因此不会出现对cout或者说控制台资源的竞争，不过本次也沿用了发送方的消息队列输出日志。
   
4. **<font size=4, color="red">锁机制：</font>**

   本次实验中由于和上次一样，同样使用了多线程来进行编程，也无比避免地涉及到对全局变量的一些操作。**为了使它们不同时对其进行读写。因此本次实验中设计采用了更为复杂的锁机制来避免竞争。不仅是日志线程的锁，甚至设计双锁机制，具体详见我的代码部分。**


#### 3.2.3 两次挥手（关闭连接）

**这里和Lab03-02也没有任何变化，可以直接跳过。详见我Lab03-02报告。**

对TCP的四次挥手进行了改进，只保留了两次挥手。

除此之外，在发送端和接收端都知道发送完毕（接收端通过最后一个包的LAS标志位）准备开始挥手后：

1. 第一次挥手：客户端（发送方）向服务器端（接收方）发送FIN=1，seq=nextseqnum的数据包，即“假装”此数据包放在了发送方的滑动窗口的新位置，是最后一个发送的数据包序列号+1；
2. 第二次挥手：服务器端（接收方）接收到了客户端（发送方）的FIN报文后，回复ACK=1，ack=nextseqnum+1的数据包，回应对方自己收到了刚才的FIN报文。挥手结束。

#### 3.2.4 Keep-Alive

基于HTTP应用层的Keep-Alive机制，即**一次连接多次传输**。

### 4 实验过程及代码讲解

**<font size=3, color=red>由于Lab03-02已经搭好了大部分的框架，因此本次在此处只重点介绍改动的核心部分（加粗）。</font>**

#### 4.1 头文件

在头文件中，我包含了一些对特殊类和宏常量等的处理，接下来结合代码详细说明，**这里同样只重点说明改动部分：**

1. 宏常量：Flags标志位的对应常量值，只使用低五位。**这里没有变化。**

   ```c++
   //Flags currently using the last six spots
   #define SYN 0x1
   #define ACK 0x2
   #define FIN 0x4
   #define LAS 0x8
   #define RST 0x10
   ```

2. 一些特殊的宏常量，**相比于上次也没有任何变化。**

   * MSS：即仿照TCP的数据段的最大长度进行设计，用于分组传输文件。MSS的值为14600字节，这意味着每个 TCP 数据段的数据部分的最大长度为14600字节。
   * UDP_SHAKE_RETRIES 10：即握手过程中超时重传最大次数，默认为10。
   * UDP_WAVE_RETRIES 10：即挥手过程中超时重传的最大次数，默认为10。
   * MSL：即仿照TCP报文的最大生命周期进行设计，一个来或者回的过程。使用计量单位是CLOCKS_PER_SEC宏常量，即每秒钟的时钟周期数。
   * PATIENCE CLOCKS_PER_SEC * 1000：用于客户端出现异常太久没有发来消息不论是挥手还是新的文件数据报文（可能是在输入文件路径）。为了避免死锁，服务器端主动结束。

3. Header类：包含了所有需要用到报文头部的分段，包含构造函数和获取函数等。**同样没有变化，就不上代码。**

4. **Datagram类：**

   之前只在发送方具有这个类，因为只有发送方才需要缓存数据报。**不过本次由于接收方可以乱序接收，因此也需要定义此类。同时在发送方，额外加入每一个数据报的计时器`Timer dg_timer`和是否被ack过的`bool is_acked`。**接收方和上次的Datagram相同即可不需要新加东西。

   ```c++
   //align 1Byte same as Header
   #pragma pack(push)
   #pragma pack(1)
   //Datagram = Header + data
   class Datagram {
   private:
   	Header header;
   	char data[MSS];
   	Timer dg_timer;
   	//For SR, if the datagram is acked, is_acked=true
   	bool is_acked;
   public:
   	Datagram() {};
   	Datagram(Header header, char* data) :header(header) {
   		memcpy(this->data, data, header.data_length);
   		is_acked = false;
   	}
   	Header& get_header() {
   		return header;
   	}
   	char* get_data() {
   		return data;
   	}
   	Timer& get_dg_timer() {
   		return dg_timer;
   	}
   	bool& get_is_acked() {
   		return is_acked;
   	}
   	void set_is_acked(bool is_acked) {
   		this->is_acked = is_acked;
   	}
   
   };
   #pragma pack(pop)
   //Resume 4Byte align
   ```

5. **ReceiveBuffer类：**

   **在接收方（服务器端）显式地定义了一个类叫做接收缓冲区类**，用来保存send_base等变量，同时保存滑动窗口，还使用了一个锁，具体而言：

   * 成员变量：
     * **u_short send_base：**即滑动窗口后沿，也是发送缓冲区的后沿。
     * **deque<Datagram*> slide_window：**由于考虑到在发送数据过程中，对于GBN来说，发送端的滑动窗口每次只会在窗口的前沿（这里理解为末尾）添加新的数据报，而如果有新的数据报被ack，那么它一定会从窗口的后沿（这里理解为开头）。**因此正好符合队列FILO的特征，选取双端对列是方便进行遍历。**
     * **u_short next_seq_num：**即滑动窗口后沿的下一个数据报位置。
     * **mutex buffer_lock：由于可能会有多个线程同时对全局变量（实际上是这个SendBuffer的唯一实例里面的成员变量）读或者写，为了避免竞争，对其操作前后进行锁。**

   * 成员函数：

     * Sendbuffer()：**按照状态机，send_base和next_seq_num需要初始化为1。**
     * **back_edge_slide()：滑动窗口后沿滑动，send_base变化，容器pop。**
     * **front_edge_slide(Datagram* datagram)：滑动窗口前沿滑动，next_seq_num变化，容器push。**

     **<font size=3, color="red">以上所有操作前后均需要加锁和解锁。</font>**

   ```c++
   class Receivebuffer {
   private:
   	u_short receive_base;
   	//SR for server(receiver), sliding window has the size as the buffer
   	vector<Datagram*> slide_window;
   	u_short receive_end;
   	mutex buffer_lock;
   public:
   	Receivebuffer() {
   		receive_base = 1;
   		receive_end = 1 + receive_buffer_size - 1;
   	}
   	u_short get_receive_base() {
   		return receive_base;
   	}
   	void set_receive_base(u_short receive_base) {
   		buffer_lock.lock();
   		this->receive_base = receive_base;
   		buffer_lock.unlock();
   	}
   	vector<Datagram*>& get_slide_window() {
   		return slide_window;
   	}
   	void front_edge_slide() {
   		/*
   		* Actually, it's the accpectable range getting bigger
   		*/
   		buffer_lock.lock();
   		receive_end++;
   		buffer_lock.unlock();
   	}
   	Datagram* window_edge_slide() {
   		buffer_lock.lock();
   		receive_base++;
   		// Create a copy of the first datagram in slide_window
   		Datagram* datagram = new Datagram(*slide_window[0]);
   		slide_window.erase(slide_window.begin());
   		receive_end++;
   		buffer_lock.unlock();
   		// Return the first datagram in slide_window to give it to application layer
   		return datagram;
   	}
   	Datagram* back_edge_slide() {
   		buffer_lock.lock();
   		receive_base++;
   		//return the first datagram in slide_window to give it to application layer
   		Datagram* datagram = slide_window[0];
   		slide_window.erase(slide_window.begin());
   		buffer_lock.unlock();
   		return datagram;
   	}
   	void set_receive_end(u_short receive_end) {
   		buffer_lock.lock();
   		this->receive_end = receive_end;
   		buffer_lock.unlock();
   	}
   	u_short get_receive_end() {
   		return receive_end;
   	}
   	void buff_datagram(Datagram* datagram) {
   		buffer_lock.lock();
   		slide_window.push_back(datagram);
   
   		//Sort the slide_window by sequence number every time a new datagram is put in
   		sort(slide_window.begin(), slide_window.end(), [](Datagram* a, Datagram* b) {
   			return a->get_header().get_seq() < b->get_header().get_seq();
   		});
   		buffer_lock.unlock();
   	}
   
   };
   ```

6. **Timer类：**

   设置在接收方每个数据报内的计时器。**和上次也没有任何变化就不上代码了**。使用一个锁在操作成员变量前加锁和解锁，避免竞争。内容较简单，唯一值得注意的是我初始化设定：timeout = 2 * MSL，即一个来回。

7. **全局变量：**

   * **Client端：这里同样还是只重点说我改动的。**

     * **send_buffer_size：**全局变量缓冲区大小，可以在输入数据之前设定。
     * **send_over：**由于我采用了多线程的技术，其实接受线程一直在while中recv_from，为了能让它及时退出。不能单纯地使用base=next_seq_num判断，因此其实这种情况十有两种可能的（详见注释）。**因此需要一个额外的全局变量控制线程退出，用于多线程的通信。**
     * **mutex log_lock：**前面我提到过，实际上控制台也是一个全局变量会被线程竞争，这个用于作为全局的日志互斥量。**实际上全局的互斥量虽然可以保证其本身就是线程安全的，不会被打断或者同时访问。不过经过我后面的实验发现，日志还会出现打印混乱的情况。因此后面我使用了打印线程来进一步解决。**
     * **Packet_loss_range**：我这次把丢包率调整为了可以输入控制，全局变量。便于丢包测试。
     * **Latency_param**：同样地我把延时也作为全局变量来测试延时。不过这里我采用的还是和上次一样的相对论的形式。
     * **deque`<string>` log_queue**：**消息队列，用于日志线程。**
     * **log_queue_mutex**：日志消息队列的锁。
     
     ```c++
     deque<string> log_queue;//log queue for multi-thread
     mutex log_queue_mutex;//lock for log queue
     
     //GBN
     Timer client_timer;
     Sendbuffer send_buffer;
     //Maxium size of send buffer
     int send_buffer_size;
     
     //Mutex
     mutex log_lock;
     /*
     Global variable: for mutil-thread communication
     Distinguish in the case(base=next_seq_num) :
     (1)All acked, remained pkg in the send_buffer need to be sent——send_over=false
     (2)All acked, and there are nothing remaining——send_over=true
     */
     bool send_over=false;
     
     //Packet loss test(Absolute)[0-99]
     int Packet_loss_range;
     //Latency(Relatively)[0-1]
     double Latency_param;
     ```
     
   * Server端：只有**Packet_loss_range和一个对应GBN状态机的expected_sequence_num**。其它和上次没有变化。

     ```c++
     u_short expected_sequence_num = 1;
     
     
     //Packet loss test(1-100)
     int Packet_loss_range;
     ```

8. **发送端缓冲区：<font size=3, color="red">由于我理解的滑动窗口和实验要求中的存在一定区别，但实际上没有任何影响，依然是可靠的。不过我在这里还是再次强调下我的缓冲区结构——</font>**

   * **file_data_buffer：即文件数据缓冲区**，存在整个文件内容加上文件名的全部。
   * **send_buffer：即发送缓冲区**，具有**固定大小（4到32）**，由全局变量send_buffer_size控制，并且落入其中的数据包分为两个部分：已发送但是未确认的以及可用但还没发送的。
   * **sliding window：即滑动窗口**，其中前沿是send_base，后沿的下一个是next_seq_number。其中包含的数据包都是那些已发送但是未确认的，**大小会不断变化。**
   * **send_buff：用于发送某个分组时候的临时缓冲区**。

#### 4.2 握手和挥手

客户端和服务器端的握手和挥手部分都和之前Lab03-02没有任何改变，不再赘述，详见上次报告。

#### 4.3 数据传输

1. **客户端（发送方）：**

   * **void send_data(string file_path)：**和之前一样是通过文件路径获取文件内容，写入file_data_buffer中，不过这次**为了引入多线程等机制进行了一些改动**，具体而言：

     * **CreateThread启动recv_thread_main接受线程和log_thread_main日志线程。**
     * while等所有数据都被ack
     * **send_over = true通知接收线程和日志线程退出，多线程通信**
     * **WaitForSingleObject**：阻塞当前线程，等到那两个线程都结束了，再去后续处理和挥手。

     ```c++
     void send_data(string file_path){
         /*...blablabla...*/
         //Start receving thread
     	HANDLE recv_handle = CreateThread(NULL, 0, recv_thread_main, NULL, 0, NULL);
     	//Start log thread
     	HANDLE log_handle = CreateThread(NULL, 0, log_thread_main, NULL, 0, NULL);
          /*...blablabla...*/
     	while (curr_pos < total_length) {
     		int pkg_length = total_length - curr_pos >= MSS ? MSS : total_length - curr_pos;
     		bool last = total_length - curr_pos <= MSS ? true : false;
     		rdt_send(file_data_buffer + curr_pos, pkg_length, last);
     		curr_pos += MSS;
     	}
         //这时候已经都发完了，但是还需要等到滑动窗口大小变为0，即把没有ack的都ack才能退出，保证没有剩余数据包没到client了
         while (send_buffer.get_slide_window().size() != 0) {
     		continue;
     		//Wait for all the remaining pkg to be sent,then you can leave
     	}
         //Communicate with recv_thread to make sure it's finished
     	send_over = true;
     
     
     	//Block current thread to wait for recv_thread to finish
     	WaitForSingleObject(recv_handle, INFINITE);
     	//the same for log_thread
     	WaitForSingleObject(log_handle, INFINITE);
     	/* blablabla */
     }
     ```

   * **void rdt_send(char* data_buff, int pkg_length, bool last_pkg)**

     利用每个分段后的数据报进行传输发送的函数，**也进行了一些改动**，具体而言：

     * **如果此时的next_seq_num大于等于send_base+缓冲区大小，则代表缓冲区满了，利用while阻塞；**
     * send_buffer.get_next_seq_num()设置seq，Datagram* datagram = new Datagram(send_header, data_buff)设置数据报文。
     * **如果此时next_seq_num等于send_base（此时还没前沿滑动），启动计时器，因为对于GBN来说只需要为最老的滑动窗口分组设置计时器，此时该要发送的正好是最老的。**之前都被ack完踢出去了。
     * 前沿滑动：调用接口front_edge_slide。
     * sendto发送datagram
     * **输出一些有关发送的数据报文的消息，包括显示发送缓冲区状态**。不过我前面说过我最后采用了**打印日志线程**的方式解决。所以我这里实际上不是直接cout到控制台，而是先lock_guard`<mutex>`锁住语句块，然后**通过log_queue.push_back的方式将输出的string字符串push到消息队列的末端。**

     ```c++
     void rdt_send(char* data_buff, int pkg_length, bool last_pkg){
         
         /* blablabla */
         //block the thread if the send_buffer is full
     	while (send_buffer.get_next_seq_num() >= send_buffer.get_send_base() + send_buffer_size) {
     		continue;
     	}
     	
         Header send_header(send_buffer.get_next_seq_num(), 0, flag, 0, pkg_length, sizeof(Header));
     	//Inititalize datagram with header and data
     	Datagram* datagram = new Datagram(send_header, data_buff);
         
         //Only start timer for the oldest pkg from the slide window
     	if (send_buffer.get_send_base() == send_buffer.get_next_seq_num())
     		client_timer.start();
         
         //Slide window front edge slides
     	send_buffer.front_edge_slide(datagram);
         /* blablabla */
         log = sendto(
     			clientSocket,
     			(char*)datagram,
     			pkg_length + sizeof(send_header),//total length
     			0,//no flags
     			(sockaddr*)&serverAddr,
     			sizeof(sockaddr_in)
     		);
     
     		if (log == SOCKET_ERROR) {
     			//重复五次，然后发送RST，结束...
     		}
         
         //打印一些消息，包括显示发送缓冲区状态
         {
     			lock_guard<mutex> lock(log_queue_mutex);
     			log_queue.push_back("-----New Datagram-----" + string("\n"));
     			log_queue.push_back("Successfully sent datagram---" + to_string(send_header.get_data_length() + send_header.get_header_length()) + "Bytes in length." + string("\n"));
     			log_queue.push_back("Header---" + string("\n"));
     			log_queue.push_back("seq: " + to_string(send_header.get_seq()) + " , ack: " + to_string(send_header.get_ack()) + ", flag: " + to_string(send_header.get_flag()) + ", checksum: " + to_string(send_header.get_checksum()) + string("\n"));
     			log_queue.push_back("header length:" + to_string(send_header.get_header_length()) + ", data length:" + to_string(send_header.get_data_length()) + string("\n"));
     
     
     			log_queue.push_back("send_buffer:{ ");
     			for (int i = 0; i < send_buffer.get_slide_window().size(); i++) {
     				log_queue.push_back("[" + to_string(send_buffer.get_slide_window()[i]->header.get_seq()) + "]" + " ");
     			}
     
     			for (int i = send_buffer.get_next_seq_num(); i <= send_buffer.get_send_base() + send_buffer_size - 1; i++)
     				log_queue.push_back("[ ]" + string(" "));
     			log_queue.push_back("}" + string("\n"));
     		}
     }
     ```

   * **DWORD WINAPI recv_thread_main(LPVOID lpParameter)**

     就像我前面介绍的，需要专门使用一个**接收消息线程**，因此这里是这个线程的主函数。而由于接收线程来说，它**不需要在接收消息的同时再发送数据报（主线程在做，这也是多线程的目的），因此它只需要一个非阻塞模式+while+recv_from即可实现超时重发**。介绍一些重点：

     * u_long mode = 1：要一直开启非阻塞模式接收recv_from。
     * **while (true)大结构**：除非**send_over == true即全局的多线程沟通变量通知他发送结束了，才会退出。**
     * client_timer.is_timeout() == true判断是否超时
     * **for (auto dg : send_buffer.get_slide_window())，GBN的含义，一口气全部重发滑动窗口内部的分组。**
     * **int acked_num = recv_header.get_ack() + 1 - send_buffer.get_send_base();像我前面所介绍的，由于<font size=3, color="red">累计确认的效果，接收到ack后，每次不是接收到后沿的ack才去后沿滑动，而是可以一口气滑动多个。</font>**
     * **send_buffer.get_send_base() == send_buffer.get_next_seq_num()：**若此时已经没有未经确认的分组了，**timer暂停。**但如果不是这种情况，**即滑动窗口内部还有分组没发，timer应该为此时还没确认的最老分组重新开始计时。**

     ```c++
     DWORD WINAPI recv_thread_main(LPVOID lpParameter) {
     	/*
     	* Call from send_data
     	* only return when sending is over
     	*/
     	//Wait for ACK from server
     	// 开启非阻塞模式
     	u_long mode = 1;
     	ioctlsocket(clientSocket, FIONBIO, &mode);
     	recv_buff = new char[sizeof(Header)];
     	Header recv_header;
     
     	sockaddr_in tempAddr;
     	int temp_addr_length = sizeof(sockaddr_in);
     	while (true) {
     		/*
     		* Latency Test:Relatively
     		*/
     		client_timer.set_timeout(Latency_param * client_timer.get_timeout());
     
     
     		if (send_over == true) {
     			//All the pkg has been sent, and all the ACK has been received
     			//Recv thread can be closed
     			mode = 0;
     			ioctlsocket(clientSocket, FIONBIO, &mode);
     			delete[]recv_buff;
     			return 0;
     		}
     
     		//Timeout resent protocol
     		while (recvfrom(
     			clientSocket,
     			recv_buff,
     			sizeof(recv_header),
     			0,
     			(sockaddr*)&tempAddr,
     			&temp_addr_length
     		) <= -1) {
     			if (send_over) {
     				//Equally, it can end up here
     				mode = 0;
     				ioctlsocket(clientSocket, FIONBIO, &mode);
     				delete[]recv_buff;
     				return 0;
     			}
     			if (client_timer.is_timeout() == true) {
     				//Timeout
     				//Resend all the pkg in the slide window
     				for (auto dg : send_buffer.get_slide_window()) {
     
     					int log = sendto(
     						clientSocket,
     						(char*)dg,
     						dg->header.get_data_length() + dg->header.get_header_length(),
     						0,
     						(sockaddr*)&serverAddr,
     						sizeof(sockaddr_in)
     					);
     					if (log == SOCKET_ERROR) {
     						//重复五次，然后发送RST，结束
     					}
     					////lock printing, in case other thread interrupts it
     				}
     				lock_guard<mutex> log_queue_lock(log_queue_mutex);
     				log_queue.push_back("Timeout, resent datagram to server." + string("\n"));
     				client_timer.start();
     			}
     		}
     
     
     			//Receive ACK from server
     			memcpy(&recv_header, recv_buff, sizeof(recv_header));//only header is useful
     
     
     			{
     				lock_guard<mutex> log_queue_lock(log_queue_mutex);
     				log_queue.push_back("Successfully received datagram---" + to_string(recv_header.get_data_length() + recv_header.get_header_length()) + "Bytes in length." + string("\n"));
     				log_queue.push_back("Header---" + string("\n"));
     				log_queue.push_back("seq: " + to_string(recv_header.get_seq()) + " , ack: " + to_string(recv_header.get_ack()) + ", flag: " + to_string(recv_header.get_flag()) + ", checksum: " + to_string(recv_header.get_checksum()) + string("\n"));
     				log_queue.push_back("header length:" + to_string(recv_header.get_header_length()) + ", data length:" + to_string(recv_header.get_data_length()) + string("\n"));
     			}
     
     			//checksum is a local variable, no need to lock it
     			u_short cks = checksum(recv_buff, sizeof(recv_header));
     
     			if (
     				cks == 0 //not corruptied
     				&&
     				(recv_header.get_flag() & ACK) //ACK flag
     				) {
     				/*
     				If we sent 2, 3, 4, 5 in total
     				Then while we are wait for ack on 2
     				Instead, we got acknowledge on 4
     				As we know, the receiver(server) can only receive data in correct order in GBN protocol
     				So we can safely assume that 2,3,4 has been received by server
     				*/
     				int acked_num = recv_header.get_ack() + 1 - send_buffer.get_send_base();
     				if (acked_num <= 0) {
     					////ack on previous pkg
     					lock_guard<mutex> log_queue_lock(log_queue_mutex);
     					log_queue.push_back("Server has acknowledged on packages:None" + string("\n"));
     				}
     				else {
     
     					lock_guard<mutex> log_queue_lock(log_queue_mutex);
     					log_queue.push_back("Server has acknowledged on packages:");
     					for (int i = 0; i < acked_num; i++) {
     						if (i == acked_num - 1)
     							log_queue.push_back(to_string(send_buffer.get_send_base())+ "\n");
     						else
     							log_queue.push_back(to_string(send_buffer.get_send_base()) + " ");
     						send_buffer.back_edge_slide();
     					}
     
     				}
     
     				{
     					lock_guard<mutex> lock(log_queue_mutex);
     					log_queue.push_back("send_buffer:{ ");
     					for (int i = 0; i < send_buffer.get_slide_window().size(); i++) {
     						log_queue.push_back("[" + to_string(send_buffer.get_slide_window()[i]->header.get_seq()) + "]" + " ");
     					}
     					for (int i = send_buffer.get_next_seq_num(); i <= send_buffer.get_send_base() + send_buffer_size- 1; i++)
     						log_queue.push_back("[ ]" + string(" "));
     					log_queue.push_back("}" + string("\n"));
     				}
     
     			}
     			else if (cks == 0 //not corruptied
     				&&
     				recv_header.get_flag() & RST //server try to close connection
     				) {
     				lock_guard<mutex> log_queue_lock(log_queue_mutex);
     				log_queue.push_back("Server unexpected closed:Error in connection." + string("\n"));
     
     				//log_lock.lock();
     				//cout << "Server unexpected closed:Error in connection." << endl;
     				//log_lock.unlock();
     				delete[] file_data_buffer;
     				delete[] send_buff;
     				delete[] recv_buff;
     				closesocket(clientSocket);
     				system("pause");
     				WSACleanup();
     				return 0;
     			}
     			else if (
     				cks != 0 //ACK pkg probably corruptied during transmisssion
     				)
     				continue;//continue to send pkg to server
     
     			if (send_buffer.get_send_base() == send_buffer.get_next_seq_num()) {
     				client_timer.stop();
     			}
     			else {
     				client_timer.start();
     			}
     		}
     }
     ```

   * **DWORD WINAPI log_thread_main(LPVOID lpParameter)**

     前面我提到，**为了解决消息接收混乱的问题，我用了一个日志消息线程专门打印内容。而它也只需要为client的数据传输部分服务即可（这有这时候才涉及同时有多个线程需要打印日志的情况）。**因此在rdt_send和recv_thread_main中有想要打印的地方，直接push进消息队列，由它来不停while(true)打印消息队列中内容即可。

     同样通过send_over来通信，通知他退出。

     ```c++
     DWORD WINAPI log_thread_main(LPVOID lpParameter) {
     	while (true) {
     		if (send_over == true) 
     			return 0;
     		unique_lock<mutex> log_queue_lock(log_queue_mutex);
     			if (!log_queue.empty()) {
     			cout << log_queue.front();
     			log_queue.pop_front();
     		}
     		log_queue_lock.unlock();
     	}
     }
     ```

     

2. **服务器端（接收方）：**

   * **void rdt_rcv(char* data_buff, int* curr_pos, bool& waved)**
   
     这里也只介绍一些大改动部分。具体而言：
   
     * 由于接收方没有必要对数据报保留副本，如果不是想要的就扔了即可，因此没有定义datagram类，**发送ack时直接使用send_buff。**
     * 初始化send_buff的ack为**expected_sequence_num - 1**。即0。但后面一直保持着它的ack和expected_sequence_num的这个数量关系，**实际上就是如果收到的报文不是想要的，就“对连续收到的最大序列号进行确认”的累积确认效果。**
     * **recv_header.get_seq() == expected_sequence_num：如果是想要的窗口内报文**，Header ack_header(0, expected_sequence_num, ACK, 0, 0, sizeof(Header))设置头部。
     * **expected_sequence_num++**：窗口（缓冲区）滑动。
     * **如果不是想要的报文即序列号不是expected_sequence_num，发送send_buff**，就对连续收到的最大序列号进行确认了。
     * **校验和出错**，也发send_buff，连续收到的最大序列号进行确认。
     * 接收方对于**GBN来说，由于只有一个滑动窗口位置，所以它接收到想要的数据报后可以直接写入即上交给上层用户，一定保序，是可靠的。**
   
     ```c++
     void rdt_rcv(char* data_buff, int* curr_pos, bool& waved) {
     
         				/* blablabla */
     //Initialize
     	((Header*)send_buff)->flag = ACK;
     	((Header*)send_buff)->ack = expected_sequence_num - 1;//expected_sequence_num is 1 at first, ack on 0
     	((Header*)send_buff)->header_length = sizeof(Header);
     	((Header*)send_buff)->checksum = checksum(send_buff, sizeof(Header));
     	// non-blocking mode
     	/*
     	* Actully same case here for GBN
     	* For server, there is no need to program in mutil-thread
     	* Because it can complete it with a while sentence and a non-block mode
     	* All he have to do is wait for current window to be filled
     	* He don't need to send anything else while recvfrom(ing)
     	* For short:All he sending behavior happens after recvfrom(ed)
     	* But for client, it is different, he have to send data while recvfrom(ing)[pipeline]
     	*/
     	u_long mode = 1;
     	ioctlsocket(serverSocket, FIONBIO, &mode);
     	clock_t start = clock();
     	cout << "-----------Waiting for File or Waving hands-----------" << endl;
     
     
     
     	while (true) {
             /* blablabla */
             if (recv_header.get_seq() == expected_sequence_num){
                 cout<<"GBN expected datagram received!"<<endl;
     				//Send ACK
     				Header ack_header(0, expected_sequence_num, ACK, 0, 0, sizeof(Header));
     
     				//at the same time, send_buff has been changed
     				//And also the next time, a corruptied or unexpected pkg received, we can just send the send_buff
     				//expected_sequence_num will update later, so the ack in send_buff is still expected_sequence_num - 1
     				memcpy(send_buff, (char*)&ack_header, sizeof(ack_header));
     
     				//Update expected_sequence_num
     				expected_sequence_num++;
     				//show receiver sliding window
     				cout << "receiver buffer:{ [" << expected_sequence_num << "] }" << endl;
     				//so checksum again
     				u_short cks = checksum(send_buff, sizeof(ack_header));
     				((Header*)send_buff)->checksum = cks;
                 
                 /* blablabla */
                 memcpy(data_buff + *curr_pos, recv_buff + sizeof(recv_header), recv_header.get_data_length());
     				//后移curr_pos
     				*curr_pos += recv_header.get_data_length();
     				if (recv_header.get_flag() & LAS) {
     					finished = true;
     					start = clock();
     					cout << "Finished receiving file." << endl;
     					break;
     				}
             }
             
             
             /* blablabla */
             else {
     				//Unexpected datagram received
     				//Send ACK on last correctedly received package
     				int times = 5;
     			SendACK4:
     				log = sendto(serverSocket, send_buff, sizeof(Header), 0, (sockaddr*)&clientAddr, sizeof(sockaddr_in));
     				if (log == SOCKET_ERROR) {
     					cout << "Oops!Failed to send ACK to client on unexpected datagram." << endl;
     					cout << GetLastErrorDetails() << endl;
     					cout << "Please try again later." << endl;
     					//确保传过去了
     					if (!times) {
     						cout << "Failed to send ACK on unexpected pkg from client too many times." << endl;
     						cout << "------------Dismissed connection-----------" << endl;
     						//当然如果多次传不过去，客户端会多次超时重传，最后这边发不过去，对方还一直发，会造成死锁
     						//因此提前结束
     						mode = 0;
     						ioctlsocket(serverSocket, FIONBIO, &mode);
     						return;
     					}
     					times--;
     					goto SendACK4;
     				}
     				cout << "Received unexpected datagram, DROP it away." << endl;
     				//show receiver sliding window
     				cout << "receiver buffer:{ [" << expected_sequence_num << "] }" << endl;
     				cout << "Ack on last correctedly received package sent." << endl;
             
         }
              /* blablabla */
     	
     	
     }
     ```

#### 4.4 窗口大小与延时丢包测试

本次我对上次的程序进一步优化，**我将延时与丢包的测试封装为了可以在传输文件之前选择的形式，这样就无需使用中间路由器过渡进行处理了。**同样的窗口大小我也可以在传输之前改变。另外我结合了**我上次的Keep-Alive，现在每次重新传输都可以重新设置丢包率、延时与窗口大小。**

1. **延时部分：**为了模拟网络中的网络延迟，我使用了类似**”相对论“**的形式。由此实现越来越不耐心，相对地就等于时间越来越长了。**实现方法是将timer的timeout变量通过一个Latency_param将其不断缩小。不过我的延时只设置了对于发送方发送数据报的延时。没有对接收方ack进行延时，不过实际上和ack丢失情况可以看作一样，所以这里不再实现模拟。**

   ```c++
   //client的recv_thread_main中
   while (true) {
       /* blablabla */
   		/*
   		* Latency Test:Relatively
   		*/
   		client_timer.set_timeout(Latency_param * client_timer.get_timeout());
       /* blablabla */
   }
   
   //client的main中：
   /* blablabla */
   while (true) {
   				cout << "-----------Latency Test-----------" << endl;
   				cout << "Please input the latency of time in transfer:" << endl;
   				cout << "Slight Greater than 0:Severe Latency         1:No Latency" << endl;
   				cout << "Latency parameter(0-1]:";
   				cin >> Latency_param;
   				if (Latency_param <= 0 || Latency_param > 1) {
   					cout << "Latency paramter out of range, please input again." << endl;
   					continue;
   				}
   				else {
   					break;
   				}
   			}
   /* blablabla */
   	
   ```

2. **丢包测试：在发送报文和握手挥手都实现了丢包的测试，采用随机数的架构。同样地在数据传输过程中也支持丢包测试，对client的报文和server的ack都有丢包测试。**

   ```c++
   // 生成随机数
   //client的shake_hand，wave_hand，rdt_send中
   //server的rdt_recv中
   	int randomNumber = rand() % 100; //确保数字在0-99范围内
   
   	if (randomNumber <= Packet_loss_range) {
   		lock_guard<mutex> log_queue_lock(log_queue_mutex);
   		log_queue.push_back("------------DROP PACKAGE ON PURPOSE!-----------"+ string("\n"));
   	}
   	else {
   	//正常处理。。。
   	}
   
   
   //client和server的main中：
   cout << "-----------Packet Loss-----------" << endl;
   			cout<<"Please input the loss of packet in transfer:"<<endl;
   			cout<<"Less than 0:No loss         Greater than 99:All loss" << endl;
   			cout << "Packet loss rate:";
   			cin >> Packet_loss_range;
   ```

3. **窗口大小可调：**

   ```c++
   //clinet的main中
   int new_buffer_size;
   			while (true) {
   				cout << "-----------Buffer Size-----------" << endl;
   				cout<<"Please input the size of send buffer:"<<endl;
   				cout << "Size range[4-32]:";
   				cin >> new_buffer_size;
   				if (new_buffer_size < 4 || new_buffer_size > 32) {
   					cout << "Size out of range, please input again." << endl;
   					continue;
   				}
   				else {
   					send_buffer_size = new_buffer_size;
   					break;
   				}
   			}
   ```

#### 4.5 实验探索与思考

#### 5.1 正常传输

1. **握手：**进来直接开始握手：可以看到三个阶段成功实现，握手成功！
   
2. **传输数据：**这里由于为了模拟正常传输，**所以进入选择数据报文丢失率和延时都设置为没有，发送缓冲区大小（即实验要求写的窗口大小）由于为了测试4-32大小的四个测试文件，选择对应缓冲区大小依次为4, 13, 22, 32。依次传输四个文件**，设置如下：

   然后**默认都输出到我的Github本次仓库位置D:\Github下**，下面展示实验的结果：

   * **测试文件1：缓冲区大小为4。**

   * **测试文件2：缓冲区大小为13。**

   * **测试文件3：缓冲区大小为22。**

   * **测试文件4：缓冲区大小为32。**

**<font size=3, color="red">可以看到所有文件全部能够在没有丢包和延时的条件下传输成功，图片能够正常显示画面，txt能够显示中英文，并且大小字节也和给定图片相同。</font>**

2. 延时传输：通过之前说的**相对论**方式测试，**选择参数设置为Latency Paramter0.2，丢包率设置为-1即没有，选择缓冲区大小即18，选取测试文件2进行测试**，设置如下：

不过**这次传输的文件命名为22.jpg，还在地址D:\Github下**，结果如下：

**可以看到成功实现了传输，文件大小内容没有变化，且图片也能够正常显示。现在我们看看传输过程中的细节：**

我们抽取其中的一个超时重传过程，可以看到：

* **发送方（客户端）：**send_buffer中403，404，405都没有被传过去，而是一直接收到402包的ack。所以403包最后超时，触发重传（**可以看到提示Timeout, resent datagram to server**）。

* **接收方（服务器端）：**recv_buffer中一直都是403，看到此时它一直收到的都是402的包，不是他期望的，都被扔掉了，并且不停回复403的包。这是因为在403之前，客户端已经不停地在重发400，401，402等包，刚刚来到服务器端，而400，401，402之所以被不停重发，**本质原因是我的延时测试是一个累积的效果**，我在每次收到新的包后都会把timeout设置为原来的0.2，**所以超时时间会越来越短，相当于延时越来越严重，导致的结果。**

  **不过最后403包还是重传到了服务器端，解决问题了。**

**<font size=3, color="red">到此可以看到，延时测试非常成功！</font>**

**3.丢包：同样地，此时测试丢包，因此设置延时为不存在（1），然后设置丢包率（握手+客户端数据报+服务器端ack+挥手）为Packet_loss=4，即5%。选择缓冲区大小为18，选取测试文件2进行测试。**设置如下：

不过**这次传输的文件命名为222.jpg，还在地址D:\Github下**，结果如下：

**可以看到成功实现了传输，文件大小内容没有变化，且图片也能够正常显示。现在我们看看传输过程中的细节：**

我们抽取其中的一个丢包过程，可以看到：

* **接收方（服务器端）**：在接收到384序列号后，本来打算回复385的ack，**结果被丢包了（可以看到提示DROP PACKAGE ON PURPOSE）。**
* **发送方（客户端）：**看到收到383的ack后接下来收到的就是385的ack，384的gap了。**但是没有影响，因为累积确认的效果**，所以一口气可以把384和385都踢出窗口，这是因为如果接收方没接收到384的包，不可能发385的ack。**可以放心进行ack丢失的错误处理。**

**<font size=5, color="red">综上所诉，对所有功能都进行了测验，均证明实现非常成功！</font>**

#### 5.4 测试结果总结

**在这里总结本次实验使用流水线协议的多序号流量控制+GBN累积确认，使用发送窗口大小变化，没有延时和丢包的情况下对四个测试文件的传输数据总大小（我这里包括了文件路径）、时延以及吞吐率的结果**，以表格形式呈现，具体截图在前面可以找到：

| Test File/Result | Buffer Size | Total length(Bytes) | Total time(ms) | Throughoutput(Bytes/ms) |
| ---------------- | ----------- | ------------------- | -------------- | ----------------------- |
| 1                | 4           | 1857459             | 2307           | 805.14                  |
| 2                | 13          | 5898611             | 25607          | 230.352                 |
| 3                | 22          | 11969100            | 43594          | 274.558                 |
| 4                | 32          | 1655923             | 3629           | 456.303                 |

#### 5.5 图形结果分析



### **6 实验反思与总结	**

#### 6.1 实验总结

**本次实验我通过在Lab03-02的基于多序号流水线协议上进一步实现了选择重传协议。避免了GBN带来的大量重传的资源浪费。**具体而言实现了：

* 流水线协议：流量控制与多个序列号
* **选择确认：Selected Repeat**
* 可以交互改变的**双方窗口大小、改进的延时与丢包测试**
* **发送方和接收方都设置多线程**实现数据传输与保序的日志输出
* **更为复杂的锁机制**避免竞争
* **Keep-Alive**一次握手多次传输

#### 6.2 实验改进方向

虽然**本次实验非常完整地实现了所有的功能，甚至额外实现了一些更好地交互与封装，实现了传输的更加可靠**，不过通过我的观察，我还是发现了一些隐藏的小瑕疵，暂时我还没有解决，有待完善。

1. 上次
2. 由于本次实验要求中
3. HTTP协议的状态码：可以考虑加入类似于HTTP1.1中更多的OK那种状态码。
4. 数据包格式中加入IP和端口号等。
4. Keep-Alive机制必须得服务器端输出完文件后才能进行挥手，否则有问题。

#### 6.3 实验总结与收获

总的来说，**本次实验通过亲自在RDT3.0上进一步实现流水线协议的流量控制与GBN的累积确认，对其中过程和很多错误处理机制都进行了实现，还进一步完善了很多功能。让我收获颇丰。**

通过和助教学长的讨论也让我再次明白了很多，**感谢助教学长与吴英老师，我会继续努力学习本课程，并在基础上发挥自己的创造力，探索更多可能性。**
